{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets.fastspeech_dataset import (\n",
    "    build_path_to_transcript_dict_libri_tts,\n",
    "    FastSpeechDataset, Miniset\n",
    ")\n",
    "from pipelines.gst_fastspeech2 import meta_train_loop\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_BASE_PATH = '../data/librispeech'\n",
    "# TEST_CLEAN_PATH = os.path.join(DATASET_BASE_PATH, 'test-clean')\n",
    "TEST_CLEAN_PATH = '/home/nmmy/Documents/dataset/test-clean/'\n",
    "TRAIN_CLEAN_PATH = os.path.join(DATASET_BASE_PATH, 'train-clean-100')\n",
    "ALIGNER_CHECKPOINT = \"/home/nmmy/Documents/dataset/aligner.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_dict = build_path_to_transcript_dict_libri_tts(TEST_CLEAN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only test on 100 samples\n",
    "transcript_dict_100 = {}\n",
    "for i,(k,v) in enumerate(transcript_dict.items()):\n",
    "    if i == 100: break\n",
    "    transcript_dict_100[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FastSpeechDataset(\n",
    "    path_to_transcript_dict=transcript_dict,\n",
    "    acoustic_checkpoint_path=ALIGNER_CHECKPOINT,  # path to aligner.pt\n",
    "    cache_dir=\"./librispeech\",\n",
    "    lang=\"en\",\n",
    "    loading_processes=4,  # depended on how many CPU you have\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spkId = os.path.join(TEST_CLEAN_PATH, '61')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minidataset = Miniset(dataset, speakerID='61')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetlist = [minidataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tts.models.fastspeech2.FastSpeech2 import FastSpeech2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FastSpeech2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_loop.train_loop(net,datasetlist, \n",
    "                           device='cpu', \n",
    "                           batch_size=2,\n",
    "                           save_directory='.',\n",
    "                           path_to_checkpoint=None,\n",
    "                           phase_1_steps=2,\n",
    "                           phase_2_steps=2,\n",
    "                           steps_per_checkpoint=1,\n",
    "                           path_to_embed_model='/home/nmmy/Documents/dataset/embedding_function.pt',\n",
    "                           lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
