{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "from IPython.display import Audio\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from numpy import trim_zeros\n",
    "\n",
    "from src.spk_embedding.StyleEmbedding import StyleEmbedding\n",
    "from src.tts.vocoders.hifigan.HiFiGAN import HiFiGANGenerator\n",
    "from src.tts.models.fastporta.FastPorta import FastPorta\n",
    "from src.tts.models.fastporta.FastPorta2 import FastPorta2\n",
    "from src.tts.models.fastporta.FastPorta3 import FastPorta3\n",
    "from src.tts.models.fastporta.FastPortaVAE import FastPortaVAE\n",
    "from src.tts.models.fastspeech2.FastSpeech2 import FastSpeech2\n",
    "from src.datasets.fastspeech_dataset import (\n",
    "    FastSpeechDataset,\n",
    "    build_path_to_transcript_dict_libri_tts,\n",
    ")\n",
    "from src.utility.tokenizer import ArticulatoryCombinedTextFrontend as Tokenizer\n",
    "\n",
    "from src.preprocessing.audio_processing import AudioPreprocessor\n",
    "\n",
    "from src.pipelines.fastporta.train_loop import collate_and_pad\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CLEAN_PATH = '../data/test-clean'\n",
    "\n",
    "AVOCODO_CHECKPOINT = \"../saved_models/Avocodo.pt\"\n",
    "ALIGNER_CHECKPOINT = \"../saved_models/aligner.pt\"\n",
    "FASTPORTA_CHECKPOINT = \"../saved_models/fastporta/fastporta_checkpoint_lastest.pt\"\n",
    "FASTPORTA2_CHECKPOINT = \"../saved_models/fastporta/fastporta2_parallel_p1-0.5_checkpoint_lastest.pt\"\n",
    "FASTPORTA3_CHECKPOINT = \"../saved_models/fastporta/fastporta4_checkpoint_260.pt\"\n",
    "FASTPORTAVAE_CHECKPOINT = \"../saved_models/fastporta/fastporta-vae_checkpoint_lastest.pt\"\n",
    "FASTSPEECH2_CHECKPOINT = \"../saved_models/fastspeech2/fastspeech2_checkpoint_lastest.pt\"\n",
    "STYLE_EMBED_CHECKPOINT = \"../saved_models/embedding_function.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_dict = build_path_to_transcript_dict_libri_tts(TEST_CLEAN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FastSpeechDataset(\n",
    "    path_to_transcript_dict=transcript_dict,\n",
    "    acoustic_checkpoint_path=ALIGNER_CHECKPOINT,  # path to aligner.pt\n",
    "    cache_dir=\"./librispeech\",\n",
    "    lang=\"en\",\n",
    "    loading_processes=2,  # depended on how many CPU you have\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocoder = HiFiGANGenerator().to(device)\n",
    "avocodo_check_dict = torch.load(AVOCODO_CHECKPOINT, map_location=device)\n",
    "vocoder.load_state_dict(avocodo_check_dict[\"generator\"])\n",
    "vocoder.eval()\n",
    "\n",
    "style_embed_function = StyleEmbedding().to(device)\n",
    "style_embed_check_dict = torch.load(STYLE_EMBED_CHECKPOINT, map_location=device)\n",
    "style_embed_function.load_state_dict(style_embed_check_dict[\"style_emb_func\"])\n",
    "style_embed_function.eval()\n",
    "style_embed_function.requires_grad_(False)\n",
    "\n",
    "acoustic_model = FastPorta3().to(device)\n",
    "check_dict = torch.load(FASTPORTA3_CHECKPOINT, map_location=device)\n",
    "# acoustic_model = FastPorta2(mix_style_p=0).to(device)\n",
    "# check_dict = torch.load(FASTPORTA2_CHECKPOINT, map_location=device)\n",
    "# acoustic_model = FastPorta3().to(device)\n",
    "# check_dict = torch.load(FASTPORTA3_CHECKPOINT, map_location=device)\n",
    "# acoustic_model = FastPortaVAE().to(device)\n",
    "# check_dict = torch.load(FASTPORTAVAE_CHECKPOINT, map_location=device)\n",
    "# acoustic_model = FastSpeech2().to(device)\n",
    "# check_dict = torch.load(FASTSPEECH2_CHECKPOINT, map_location=device)\n",
    "acoustic_model.load_state_dict(check_dict[\"model\"])\n",
    "acoustic_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref audio\n",
    "\n",
    "sample_id = 15\n",
    "sample = dataset[sample_id]\n",
    "input_audio_path = sample[-1]\n",
    "input_wave, sr = sf.read(input_audio_path)\n",
    "input_text = transcript_dict[input_audio_path]\n",
    "batch = collate_and_pad([sample])\n",
    "print(\"Path: \", input_audio_path)\n",
    "print(\"Text: \", input_text)\n",
    "Audio(data=input_wave, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another text\n",
    "\n",
    "text_sample_id = 4\n",
    "text_sample = dataset[text_sample_id]\n",
    "text_batch=collate_and_pad([text_sample])\n",
    "text_input = transcript_dict[text_sample[-1]]\n",
    "print(text_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_embedding = style_embed_function(\n",
    "    batch_of_spectrograms=batch[2].to(device),\n",
    "    batch_of_spectrogram_lengths=batch[3].to(device),\n",
    ")\n",
    "\n",
    "mel = acoustic_model.inference(\n",
    "    text=text_batch[0][0].to(device),\n",
    "    speech=None,\n",
    "    alpha=1.0,\n",
    "    utterance_embedding=style_embedding[0],\n",
    "    return_duration_pitch_energy=False,\n",
    "    lang_id=batch[8][0].to(device),\n",
    ")\n",
    "\n",
    "waveform = vocoder(mel.transpose(1, 0))[0]\n",
    "waveform = waveform.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torchaudio.save(\n",
    "    'origin.wav',\n",
    "    src=torch.Tensor(input_wave).unsqueeze(0),\n",
    "    sample_rate=16000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\n",
    "    'synth.wav',\n",
    "    src=waveform,\n",
    "    sample_rate=24000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_TO_CHECKPOINTS = '../saved_models/fastporta'\n",
    "PATH_TO_CHECKPOINTS = '../saved_models/fastspeech2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastSpeech2(\n",
       "  (encoder): Conformer(\n",
       "    (embed): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=100, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=100, out_features=384, bias=True)\n",
       "    )\n",
       "    (pos_enc): RelPositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (output_norm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (hs_emb_projection): Linear(in_features=448, out_features=384, bias=True)\n",
       "    (language_embedding): Embedding(8000, 384)\n",
       "    (encoders): MultiSequential(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (duration_predictor): DurationPredictor(\n",
       "    (conv): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (dropouts): ModuleList(\n",
       "      (0-1): 2 x Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-1): 2 x LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (pitch_predictor): VariancePredictor(\n",
       "    (conv): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(384, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (1-4): 4 x Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (dropouts): ModuleList(\n",
       "      (0-4): 5 x Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-4): 5 x LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (pitch_embed): Sequential(\n",
       "    (0): Conv1d(1, 384, kernel_size=(1,), stride=(1,))\n",
       "    (1): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (energy_predictor): VariancePredictor(\n",
       "    (conv): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (dropouts): ModuleList(\n",
       "      (0-1): 2 x Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-1): 2 x LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (energy_embed): Sequential(\n",
       "    (0): Conv1d(1, 384, kernel_size=(1,), stride=(1,))\n",
       "    (1): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (length_regulator): LengthRegulator()\n",
       "  (decoder): Conformer(\n",
       "    (pos_enc): Sequential(\n",
       "      (0): RelPositionalEncoding(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (output_norm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (hs_emb_projection): Linear(in_features=448, out_features=384, bias=True)\n",
       "    (encoders): MultiSequential(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (self_attn): RelPositionMultiHeadedAttention(\n",
       "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (feed_forward): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (feed_forward_macaron): MultiLayeredConv1d(\n",
       "          (w_1): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (conv_module): ConvolutionModule(\n",
       "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
       "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "          (activation): Swish()\n",
       "        )\n",
       "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feat_out): Linear(in_features=384, out_features=80, bias=True)\n",
       "  (postnet): PostNet(\n",
       "    (postnet): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(80, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): Tanh()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1-3): 3 x Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): Tanh()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv1d(256, 80, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): GroupNorm(20, 80, eps=1e-05, affine=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): FastSpeech2Loss(\n",
       "    (l1_criterion): L1Loss()\n",
       "    (mse_criterion): MSELoss()\n",
       "    (duration_criterion): DurationPredictorLoss(\n",
       "      (criterion): MSELoss()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acoustic_model = FastSpeech2().to(device)\n",
    "acoustic_model.load_state_dict(torch.load(os.path.join(PATH_TO_CHECKPOINTS, 'checkpoint_lastest.pt'), \n",
    "                                     map_location=device)[\"model\"])\n",
    "acoustic_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_EMBED_CHECKPOINT='../saved_models/embedding_function.pt'\n",
    "AVOCODO_CHECKPOINT='../saved_models/Avocodo.pt'\n",
    "\n",
    "style_embed_function = StyleEmbedding().to(device)\n",
    "style_embed_check_dict = torch.load(STYLE_EMBED_CHECKPOINT, map_location=device)\n",
    "style_embed_function.load_state_dict(style_embed_check_dict[\"style_emb_func\"])\n",
    "style_embed_function.eval()\n",
    "style_embed_function.requires_grad_(False)\n",
    "\n",
    "vocoder = HiFiGANGenerator().to(device)\n",
    "avocodo_check_dict = torch.load(AVOCODO_CHECKPOINT, map_location=device)\n",
    "vocoder.load_state_dict(avocodo_check_dict[\"generator\"])\n",
    "vocoder.eval()\n",
    "\n",
    "ap = AudioPreprocessor(input_sr=16000, output_sr=16000, melspec_buckets=80,\n",
    "            hop_length=256,n_fft=1024,cut_silence=False,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, ref_path, acoustic_model, ap, style_embed_function, vocoder, alpha=1.0, lang=\"en\"):\n",
    "    wave, sr = sf.read(ref_path)\n",
    "    norm_wave = ap.audio_to_wave_tensor(normalize=True, audio=wave)\n",
    "\n",
    "    norm_wave = torch.tensor(trim_zeros(norm_wave.numpy()))\n",
    "    cached_speech = ap.audio_to_mel_spec_tensor(\n",
    "        audio=norm_wave, normalize=False, explicit_sampling_rate=16000\n",
    "    ).transpose(0, 1)\n",
    "\n",
    "    cached_speech_len = torch.LongTensor([len(cached_speech)])\n",
    "    cached_speech = cached_speech.unsqueeze(0)\n",
    "    tokenizer = Tokenizer(language=lang)\n",
    "    embed_text = tokenizer.string_to_tensor(\n",
    "        text, handle_missing=False, input_phonemes=False\n",
    "    )\n",
    "\n",
    "    style_embedding = style_embed_function(\n",
    "        batch_of_spectrograms=cached_speech.to(device),\n",
    "        batch_of_spectrogram_lengths=cached_speech_len.to(device),\n",
    "    )\n",
    "\n",
    "    mel = acoustic_model.inference(\n",
    "        text=embed_text.to(device),\n",
    "        speech=None,\n",
    "        alpha=alpha,\n",
    "        utterance_embedding=style_embedding[0],\n",
    "        return_duration_pitch_energy=False,\n",
    "        lang_id=torch.Tensor([[12]])[0].to(dtype=torch.int64, device=device),\n",
    "    )\n",
    "    waveform = vocoder(mel.transpose(1, 0))[0]\n",
    "    waveform = waveform.detach().cpu()\n",
    "\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The late astounding events, however, had rendered Procope manifestly uneasy, and not the less so from his consciousness that the count secretly partook of his own anxiety'\n",
    "ref_path = '../data/test-clean/5105/28241/5105-28241-0009.flac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = inference(text, ref_path, acoustic_model, ap, style_embed_function, vocoder, alpha=1.0, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\n",
    "    'synth.wav',\n",
    "    src=waveform,\n",
    "    sample_rate=24000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
